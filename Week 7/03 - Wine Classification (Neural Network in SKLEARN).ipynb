{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Introduction #2\n",
    "\n",
    "This exercise is adapted from https://www.springboard.com/blog/beginners-guide-neural-network-in-python-scikit-learn-0-18/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have successfully used SciKit Learn's MLP to work on the built-in Breast Cancer Data Set, let's try another one!\n",
    "\n",
    "Download the wine dataset from UCI Machine learning repository (http://archive.ics.uci.edu/ml/datasets/Wine/). Import the dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv('./Data/Wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the dataframe - what are the first few rows of data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0    14.23        1.71  2.43          15.6        127           2.80   \n",
       "1    13.20        1.78  2.14          11.2        100           2.65   \n",
       "2    13.16        2.36  2.67          18.6        101           2.80   \n",
       "3    14.37        1.95  2.50          16.8        113           3.85   \n",
       "4    13.24        2.59  2.87          21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280  Proline  Customer_Segment  \n",
       "0   3.92     1065                 1  \n",
       "1   3.40     1050                 1  \n",
       "2   3.17     1185                 1  \n",
       "3   3.45     1480                 1  \n",
       "4   2.93      735                 1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Alcohol               178 non-null    float64\n",
      " 1   Malic_Acid            178 non-null    float64\n",
      " 2   Ash                   178 non-null    float64\n",
      " 3   Ash_Alcanity          178 non-null    float64\n",
      " 4   Magnesium             178 non-null    int64  \n",
      " 5   Total_Phenols         178 non-null    float64\n",
      " 6   Flavanoids            178 non-null    float64\n",
      " 7   Nonflavanoid_Phenols  178 non-null    float64\n",
      " 8   Proanthocyanins       178 non-null    float64\n",
      " 9   Color_Intensity       178 non-null    float64\n",
      " 10  Hue                   178 non-null    float64\n",
      " 11  OD280                 178 non-null    float64\n",
      " 12  Proline               178 non-null    int64  \n",
      " 13  Customer_Segment      178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "# find out the attributes in the dataset\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out the total instances and number of features\n",
    "wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>178.0</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>11.03</td>\n",
       "      <td>12.3625</td>\n",
       "      <td>13.050</td>\n",
       "      <td>13.6775</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic_Acid</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.6025</td>\n",
       "      <td>1.865</td>\n",
       "      <td>3.0825</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.5575</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>10.60</td>\n",
       "      <td>17.2000</td>\n",
       "      <td>19.500</td>\n",
       "      <td>21.5000</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>178.0</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>70.00</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>107.0000</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.7425</td>\n",
       "      <td>2.355</td>\n",
       "      <td>2.8000</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.2050</td>\n",
       "      <td>2.135</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.555</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_Intensity</th>\n",
       "      <td>178.0</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.2200</td>\n",
       "      <td>4.690</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280</th>\n",
       "      <td>178.0</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.1700</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>178.0</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>278.00</td>\n",
       "      <td>500.5000</td>\n",
       "      <td>673.500</td>\n",
       "      <td>985.0000</td>\n",
       "      <td>1680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_Segment</th>\n",
       "      <td>178.0</td>\n",
       "      <td>1.938202</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count        mean         std     min       25%  \\\n",
       "Alcohol               178.0   13.000618    0.811827   11.03   12.3625   \n",
       "Malic_Acid            178.0    2.336348    1.117146    0.74    1.6025   \n",
       "Ash                   178.0    2.366517    0.274344    1.36    2.2100   \n",
       "Ash_Alcanity          178.0   19.494944    3.339564   10.60   17.2000   \n",
       "Magnesium             178.0   99.741573   14.282484   70.00   88.0000   \n",
       "Total_Phenols         178.0    2.295112    0.625851    0.98    1.7425   \n",
       "Flavanoids            178.0    2.029270    0.998859    0.34    1.2050   \n",
       "Nonflavanoid_Phenols  178.0    0.361854    0.124453    0.13    0.2700   \n",
       "Proanthocyanins       178.0    1.590899    0.572359    0.41    1.2500   \n",
       "Color_Intensity       178.0    5.058090    2.318286    1.28    3.2200   \n",
       "Hue                   178.0    0.957449    0.228572    0.48    0.7825   \n",
       "OD280                 178.0    2.611685    0.709990    1.27    1.9375   \n",
       "Proline               178.0  746.893258  314.907474  278.00  500.5000   \n",
       "Customer_Segment      178.0    1.938202    0.775035    1.00    1.0000   \n",
       "\n",
       "                          50%       75%      max  \n",
       "Alcohol                13.050   13.6775    14.83  \n",
       "Malic_Acid              1.865    3.0825     5.80  \n",
       "Ash                     2.360    2.5575     3.23  \n",
       "Ash_Alcanity           19.500   21.5000    30.00  \n",
       "Magnesium              98.000  107.0000   162.00  \n",
       "Total_Phenols           2.355    2.8000     3.88  \n",
       "Flavanoids              2.135    2.8750     5.08  \n",
       "Nonflavanoid_Phenols    0.340    0.4375     0.66  \n",
       "Proanthocyanins         1.555    1.9500     3.58  \n",
       "Color_Intensity         4.690    6.2000    13.00  \n",
       "Hue                     0.965    1.1200     1.71  \n",
       "OD280                   2.780    3.1700     4.00  \n",
       "Proline               673.500  985.0000  1680.00  \n",
       "Customer_Segment        2.000    3.0000     3.00  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use describe to find out more about the data\n",
    "wine.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine['Customer_Segment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** what can you say about this dataset?\n",
    "\n",
    "\n",
    "- There's no missing value\n",
    "- Each feature's data is widely distributed, standardization is needed\n",
    "- Target is fairly distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set up the data (x) and labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = wine.values\n",
    "X = dataset[:,0:-1].astype(float)\n",
    "y = dataset[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split\n",
    " \n",
    "Let's split our data into training and testing sets, this is done easily with SciKit Learn's train_test_split function from model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    " \n",
    "The neural network may have difficulty converging before the maximum number of iterations allowed if the data is not normalized. Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. Note that you must apply the same scaling to the test set for meaningful results. There are a lot of different methods for normalization of data, we will use the built-in StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the StandardScalar library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train  = sc.transform (X_train)\n",
    "X_test  = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    " \n",
    "Now it is time to train our model. SciKit Learn makes this incredibly easy, by using estimator objects. In this case we will import our estimator (the Multi-Layer Perceptron Classifier model) from the neural_network library of SciKit-Learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an instance of the model, there are a lot of parameters you can choose to define and customize here, we will only define the hidden_layer_sizes. For this parameter you pass in a tuple consisting of the number of neurons you want at each layer, where the nth entry in the tuple represents the number of neurons in the nth layer of the MLP model. There are many ways to choose these numbers, but for simplicity we will choose 3 layers with the same number of neurons as there are features in our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Multilayerperceptron classifier and call it mlp\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13, 13, 13), random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been made we can fit the training data to our model, remember that this data has already been processed and scaled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf  = mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What do you see in the output? What does it tell you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maximum iterations reached and optimization hasn't converged\n",
    "- More run is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and Evaluation\n",
    " \n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the predict() method off of our fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use SciKit-Learn's built in metrics such as a classification report and confusion matrix to evaluate how well our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       1.00      1.00      1.00        14\n",
      "         3.0       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** what conclusion can you make from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seems overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and biases\n",
    "\n",
    "The downside however to using a Multi-Layer Preceptron model is how difficult it is to interpret the model itself. The weights and biases won't be easily interpretable in relation to which features are important to the model itself.\n",
    "\n",
    "To extract the MLP weights and biases after training your model, you use its public attributes coefs_ and intercepts_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "------------------------------\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "------------------------------\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "13,13\n",
      "------------------------------\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "13,3\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficient values and interpret it\n",
    "\n",
    "for x in mlp.coefs_:\n",
    "    for y in x:\n",
    "        print(str(len(x)) + ',' + str(len(y)))\n",
    "    print(\"------------------------------\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "13\n",
      "13\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Print the intercepts values and interpret it\n",
    "\n",
    "for x in mlp.intercepts_:\n",
    "    print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.22572696,  0.2816932 , -0.30564877,  0.0957832 , -0.15453563,\n",
       "         0.27942284, -0.27653215,  0.23465765, -0.1601996 ,  0.59171998,\n",
       "        -0.19943846, -0.27326665, -0.19084976]),\n",
       " array([ 0.18914649,  0.25914756, -0.22958128, -0.33456865,  0.17590116,\n",
       "        -0.27990709,  0.16098038,  0.59318125,  0.0963413 ,  0.0421705 ,\n",
       "         0.32740759, -0.05459201,  0.0950298 ]),\n",
       " array([ 0.15279442,  0.18728225,  0.33802072,  0.51162939, -0.08293407,\n",
       "        -0.14642472, -0.18605553,  0.52777391,  0.25236106, -0.26769042,\n",
       "         0.28575722,  0.01030555, -0.21594643]),\n",
       " array([-0.12799852, -0.43272747, -0.57001619])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.intercepts_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** What do you understand from the two values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coefs seems to be input (I)?\n",
    "- Intercepts is the weight (W)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional optional tasks...\n",
    "\n",
    "select a few known supervised techniques and compare their performance. Use 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "seed = 42\n",
    "\n",
    "def train_and_test_model(X_train, y_train, X_test, y_test, model):\n",
    "    cv = StratifiedKFold(10, shuffle=True, random_state=seed)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91 accuracy with a standard deviation of 0.08\n",
      "[[13  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  1  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.93      0.96        14\n",
      "         2.0       0.88      1.00      0.93        14\n",
      "         3.0       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "train_and_test_model(X_train, y_train, X_test, y_test, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 accuracy with a standard deviation of 0.05\n",
      "[[14  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       1.00      1.00      1.00        14\n",
      "         3.0       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "train_and_test_model(X_train, y_train, X_test, y_test, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94 accuracy with a standard deviation of 0.06\n",
      "[[14  0  0]\n",
      " [ 1 13  0]\n",
      " [ 0  1  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      1.00      0.97        14\n",
      "         2.0       0.93      0.93      0.93        14\n",
      "         3.0       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt = GradientBoostingClassifier()\n",
    "train_and_test_model(X_train, y_train, X_test, y_test, gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 accuracy with a standard deviation of 0.05\n",
      "[[14  0  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        14\n",
      "         2.0       1.00      1.00      1.00        14\n",
      "         3.0       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tangkaiv\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(13, 13, 13), random_state=42)\n",
    "train_and_test_model(X_train, y_train, X_test, y_test, mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
